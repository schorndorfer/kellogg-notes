{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textacy documentation: https://chartbeat-labs.github.io/textacy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Since the so-called \"statistical revolution\" in the late 1980s and mid 1990s, '\n",
    "    'much Natural Language Processing research has relied heavily on machine learning. '\n",
    "    'Formerly, many language-processing tasks typically involved the direct hand coding '\n",
    "    'of rules, which is not in general robust to natural language variation. '\n",
    "    'The machine-learning paradigm calls instead for using statistical inference '\n",
    "    'to automatically learn such rules through the analysis of large corpora '\n",
    "    'of typical real-world examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1980s and mid 1990s, much Natural  Language  Processing research has relied hea\n",
      "n machine learning. Formerly, many  language -processing tasks typically involve\n",
      "s not in general robust to natural  language  variation. The machine-learning pa\n"
     ]
    }
   ],
   "source": [
    "textacy.text_utils.KWIC(text, 'language', window_width=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'since the so called statistical revolution in the late 1980s and mid 1990s much natural language processing research has relied heavily on machine learning formerly many language processing tasks typically involved the direct hand coding of rules which is not in general robust to natural language variation the machine learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real world examples'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.preprocess_text(text, lowercase=True, no_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'title': 'Natural-language processing', \n",
    "    'url': 'https://en.wikipedia.org/wiki/Natural-language_processing',\n",
    "    'source': 'wikipedia'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = textacy.Doc(text, metadata=metadata, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doc(85 tokens; \"Since the so-called \"statistical revolution\" in...\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Since the so-called \"statistical revolution\" in the late 1980s and mid 1990s, much Natural Language Processing research has relied heavily on machine learning. Formerly, many language-processing tasks typically involved the direct hand coding of rules, which is not in general robust to natural language variation. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora of typical real-world examples."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.spacy_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1980s and mid, Natural Language Processing, Language Processing research, research has relied, heavily on machine, processing tasks typically, tasks typically involved, involved the direct, direct hand coding, coding of rules]\n"
     ]
    }
   ],
   "source": [
    "ngrams = list(textacy.extract.ngrams(doc, 3, filter_stops=True, filter_punct=True, filter_nums=False))\n",
    "print(ngrams[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 0.06469840439566026),\n",
       " ('rule', 0.05652651341294322),\n",
       " ('machine', 0.05257062044951949),\n",
       " ('statistical', 0.04292595119686373),\n",
       " ('natural', 0.04177948765003742),\n",
       " ('world', 0.03970175136498526),\n",
       " ('real', 0.037150947215394275),\n",
       " ('typical', 0.03554707044022466),\n",
       " ('corpora', 0.034313898275359044),\n",
       " ('large', 0.0330254168906275)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textacy.keyterms\n",
    "textacy.keyterms.textrank(doc, normalize='lemma', n_keyterms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language processing research', 0.31188112358833325),\n",
       " ('natural language variation', 0.09554941648195946),\n",
       " ('direct hand coding', 0.09461396545586934),\n",
       " ('mid 1990s', 0.05831079282180467),\n",
       " ('machine learning', 0.0552325339992006),\n",
       " ('late 1980s', 0.04713120721580818),\n",
       " ('general robust', 0.040647628278589344),\n",
       " ('statistical revolution', 0.03898147636679938)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.keyterms.sgrank(doc, ngrams=(1, 2, 3, 4), normalize='lower', n_keyterms=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_sents': 3,\n",
       " 'n_words': 73,\n",
       " 'n_chars': 414,\n",
       " 'n_syllables': 134,\n",
       " 'n_unique_words': 57,\n",
       " 'n_long_words': 30,\n",
       " 'n_monosyllable_words': 38,\n",
       " 'n_polysyllable_words': 19}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = textacy.TextStats(doc)\n",
    "ts.basic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = doc.to_bag_of_terms(\n",
    "    ngrams=(1, 2, 3), named_entities=True, weighting='count',\n",
    "    as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late 1980: 1\n",
      "mid 1990: 1\n",
      "natural language processing: 1\n",
      "since: 1\n",
      "call: 2\n",
      "statistical: 2\n",
      "revolution: 1\n",
      "late: 1\n",
      "1980: 1\n",
      "mid: 1\n",
      "1990: 1\n",
      "natural: 2\n",
      "language: 3\n",
      "processing: 1\n",
      "research: 1\n",
      "rely: 1\n",
      "heavily: 1\n",
      "machine: 2\n",
      "learning: 1\n",
      "formerly: 1\n",
      "process: 1\n",
      "task: 1\n",
      "typically: 1\n",
      "involve: 1\n",
      "direct: 1\n",
      "hand: 1\n",
      "coding: 1\n",
      "rule: 2\n",
      "general: 1\n",
      "robust: 1\n",
      "variation: 1\n",
      "the: 1\n",
      "learn: 2\n",
      "paradigm: 1\n",
      "instead: 1\n",
      "inference: 1\n",
      "automatically: 1\n",
      "analysis: 1\n",
      "large: 1\n",
      "corpora: 1\n",
      "typical: 1\n",
      "real: 1\n",
      "world: 1\n",
      "example: 1\n",
      "statistical revolution: 1\n",
      "natural language: 2\n",
      "language processing: 1\n",
      "processing research: 1\n",
      "rely heavily: 1\n",
      "machine learning: 1\n",
      "process task: 1\n",
      "task typically: 1\n",
      "typically involve: 1\n",
      "direct hand: 1\n",
      "hand coding: 1\n",
      "general robust: 1\n",
      "language variation: 1\n",
      "the machine: 1\n",
      "learn paradigm: 1\n",
      "paradigm call: 1\n",
      "call instead: 1\n",
      "statistical inference: 1\n",
      "automatically learn: 1\n",
      "large corpora: 1\n",
      "typical real: 1\n",
      "world example: 1\n",
      "1980 and mid: 1\n",
      "language processing research: 1\n",
      "research have rely: 1\n",
      "heavily on machine: 1\n",
      "process task typically: 1\n",
      "task typically involve: 1\n",
      "involve the direct: 1\n",
      "direct hand coding: 1\n",
      "coding of rule: 1\n",
      "robust to natural: 1\n",
      "natural language variation: 1\n",
      "learn paradigm call: 1\n",
      "paradigm call instead: 1\n",
      "inference to automatically: 1\n",
      "learn such rule: 1\n",
      "analysis of large: 1\n",
      "corpora of typical: 1\n"
     ]
    }
   ],
   "source": [
    "for k, v in bot.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Many Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 11.9M/11.9M [00:18<00:00, 368kB/s]"
     ]
    }
   ],
   "source": [
    "from textacy.datasets.capitol_words import *\n",
    "cw = CapitolWords()\n",
    "cw.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'capitol_words',\n",
       " 'description': 'Collection of ~11k speeches in the Congressional Record given by notable U.S. politicians between Jan 1996 and Jun 2016.',\n",
       " 'site_url': 'http://sunlightlabs.github.io/Capitol-Words/',\n",
       " 'data_dir': '/opt/conda/lib/python3.6/site-packages/textacy/data/capitol_words'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = textacy.io.read_json(\n",
    "    f\"{cw.info['data_dir']}/capitol-words-py3.json.gz\",\n",
    "    mode='rt', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc(159 tokens; \"Mr. Speaker, 480,000 Federal employees are work...\")\n"
     ]
    }
   ],
   "source": [
    "for record in records:\n",
    "    doc = textacy.Doc(record['text'], metadata=record['title'])\n",
    "    print(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = cw.records(speaker_name={'Hillary Clinton', 'Barack Obama'})\n",
    "text_stream, metadata_stream = textacy.io.split_records(records, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11.9M/11.9M [00:30<00:00, 368kB/s]"
     ]
    }
   ],
   "source": [
    "corpus = textacy.Corpus(textacy.load_spacy('en'),\n",
    "                        texts=cw.texts(speaker_party='R', chamber='House', limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Corpus(100 docs; 31410 tokens)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Doc(124 tokens; \"Mr. Speaker, I want to congratulate all of the ...\"),\n",
       " Doc(304 tokens; \"Mr. Speaker, I want to thank the gentleman, and...\"),\n",
       " Doc(1076 tokens; \"Mr. Speaker, it has been a great debate to list...\"),\n",
       " Doc(3261 tokens; \"Mr. Speaker, I think probably a good lead-in to...\"),\n",
       " Doc(2826 tokens; \"Mr. Speaker, I thank very much the gentleman fr...\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1350, 31410)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.n_docs, corpus.n_sents, corpus.n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = textacy.Vectorizer(\n",
    "    tf_type='linear', apply_idf=True, idf_type='smooth', norm='l2',\n",
    "    min_df=2, max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = vectorizer.fit_transform(\n",
    "    (doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True) for doc in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<100x1131 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6319 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = textacy.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "doc_topic_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : 2 minute   2   distinguished   mr.   minute   yield   gentleman   chairman   state   watts\n",
      "topic 1 :    people   go   want   washington   think   money   program   spend   let\n",
      "topic 2 : budget   section   level   fiscal   act   authority   outlay   year   1996   allocation\n",
      "topic 3 : remark   extend   permission   revise   mr.   give   jersey   ask   new jersey   franks\n",
      "topic 4 : student   loan   private   education   sector   money   department   department of education   application   aid\n",
      "topic 5 : ohio   time   consume   mr.   chairman   gentleman   yield   the   florida   balance\n",
      "topic 6 : resolution   concurrent   house   fiscal   senate   speaker   pursuant   fiscal year 1997   conference   1997\n",
      "topic 7 : gentlewoman   second   yield   15   10 second   ask   3   10   mr.   washington\n",
      "topic 8 : myrick   mrs.   gentlewoman   north   carolina   north carolina   2 minute   2   madam   minute\n",
      "topic 9 : hayworth   arizona   1\\1/2\\   1\\1/2\\ minute   minute   yield   mr.   gentleman   1 minute   madam\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=10):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
