{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path.cwd() / 'excerpt-p17.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, mode='r', encoding='utf-16-le') as fid:\n",
    "    lines = [line for line in fid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Record:\n",
    "    \"\"\"\n",
    "    A simple data class containing fields for each extracted line\n",
    "    \"\"\"\n",
    "    def __init__(self, dept, name, title, state, dist, salary):\n",
    "        self.dept, self.name, self.title, self.state, self.dist, self.salary = \\\n",
    "            dept, name, title, state, dist, salary\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"DEPT: {self.dept}\\nNAME: {self.name}\\nTITLE: {self.title}\\nSTATE: {self.state}\\nDIST: {self.dist}\\nSALARY: {self.salary}\"\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'dept':self.dept,\n",
    "            'name':self.name,\n",
    "            'title':self.title,\n",
    "            'state':self.state,\n",
    "            'dist':self.dist,\n",
    "            'salary':self.salary\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_regex      = r\"^\\s+([A-Z ]+)\\s+$\"\n",
    "name_regex      = r\"^\\s?([A-Z0]\\.?[a-z]*(?:\\s[A-Z0]\\.?[a-z]*){1,3}(?:,\\s*jr)?)\"\n",
    "title_regex     = r\"^\\s+((?:[A-Z][a-z]{2,},?)(?:\\s[A-z]+\\'?,?)*)\"\n",
    "state_regex     = r\"^\\s+([A-Z][a-z\\.]{0,3}(?:\\s?[A-Z][a-z\\.]{0,3})?)\"\n",
    "dist_regex      = r\"([0-9]{1,2}(?:d|th|st))\"\n",
    "salary_regex    = r\"([1-9]0?(?:,\\s?)?[0-9]{2,3})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "dept = None\n",
    "for line in lines:\n",
    "    # Look for a department match\n",
    "    dept_match = re.match(dept_regex, line, re.MULTILINE)\n",
    "    if dept_match: \n",
    "        dept = dept_match.group(1)\n",
    "        continue\n",
    "    \n",
    "    # Look for a row to extract a record. Every such row begins with a name,\n",
    "    # so if we get a name match, we'll look for the other pieces of information\n",
    "    name, title, state, dist, salary = None, None, None, None, None\n",
    "    \n",
    "    # 1: Name match\n",
    "    name_match = re.match(name_regex, line, re.MULTILINE)\n",
    "    if name_match:\n",
    "        name = name_match.group(1)\n",
    "        line = line[name_match.end(1):]\n",
    "        \n",
    "        # 2: Title match\n",
    "        title_match = re.match(title_regex, line, re.MULTILINE)\n",
    "        if title_match:\n",
    "            title = title_match.group(1)\n",
    "            line = line[title_match.end(1):]\n",
    "            \n",
    "        # 3: State match\n",
    "        state_match = re.match(state_regex, line, re.MULTILINE)\n",
    "        if state_match:\n",
    "            state = state_match.group(1)\n",
    "            state = re.sub(r\"[\\. ]\", '', state)\n",
    "            state = state.upper()\n",
    "            line = line[state_match.end(1):]\n",
    "        \n",
    "        # 4: District match\n",
    "        dist_match = re.search(dist_regex, line)\n",
    "        if dist_match:\n",
    "            dist = dist_match.group(1)\n",
    "            line = line[dist_match.end(1):]\n",
    "            \n",
    "        # 5: Salary match\n",
    "        salary_match = re.search(salary_regex, line)\n",
    "        if salary_match:\n",
    "            salary = salary_match.group(1)\n",
    "            salary = int(re.sub(r\"[, ]\", '', salary))\n",
    "\n",
    "        # Append the new record to the list of records\n",
    "        records.append(Record(dept=dept, \n",
    "                              name=name, \n",
    "                              title=title,\n",
    "                              state=state, \n",
    "                              dist=dist, \n",
    "                              salary=salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize state abbreviations with string distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://phiresky.github.io/levenshtein-demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance as td\n",
    "\n",
    "# list of state abbreviations\n",
    "state_abbrevs = [\"AK\",\"AL\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"\\\n",
    "OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
    "\n",
    "# turn into a dictionary\n",
    "states = {s:s for s in state_abbrevs}\n",
    "\n",
    "# add some entries derived from dataset\n",
    "states['DC'] = 'DC'\n",
    "states['MASS'] = 'MA'\n",
    "states['IOWA'] = 'IA'\n",
    "states['OHIO'] = 'OH'\n",
    "states['IND'] = 'IN'\n",
    "states['NDAK'] = 'ND'\n",
    "states['SDAK'] = 'SD'\n",
    "states['CALIF'] = 'CA'\n",
    "states['D'] = 'DC'\n",
    "\n",
    "# extract the keys\n",
    "state_keys = list(states.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in records:\n",
    "    if rec.state:\n",
    "        state = rec.state\n",
    "        l = [td.levenshtein(s, rec.state) for s in state_keys]\n",
    "        rec.state = states[state_keys[l.index(min(l))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rows = [rec.to_dict() for rec in records]\n",
    "df = pd.DataFrame(dict_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "df.groupby(['state'])['name'].count().plot.bar(x='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['state'])['salary'].mean().plot.bar(x='salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('records.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://explosion.ai/demos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt_text = (pathlib.Path.cwd() / 'excerpt-p17.txt').read_text(encoding='utf-16-le')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt_doc = nlp(excerpt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'IS_UPPER': True, 'IS_ALPHA': True, 'OP': '+'}, \n",
    "           {'IS_UPPER': True, 'IS_ALPHA': True, 'OP': '+'},\n",
    "           {'IS_UPPER': True, 'IS_ALPHA': True, 'OP': '+'},\n",
    "          ]\n",
    "matcher.add('upper_seq', None, pattern)\n",
    "\n",
    "matches = matcher(excerpt_doc)\n",
    "for _, start, end in matches:\n",
    "    span = excerpt_doc[start:end]\n",
    "    if len(span.text) > 10 and excerpt_doc[start-1].is_space and excerpt_doc[end].is_space:\n",
    "        print(f\"{span.text} ({start}, {end})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy with more fluent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_text = (pathlib.Path.cwd() / 'radiology.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(radiology_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiology_doc = nlp(radiology_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(radiology_doc.sents)\n",
    "for sent in sents:\n",
    "    print(f\"[SENT]: {sent.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc in radiology_doc.noun_chunks:\n",
    "    print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sents[9])\n",
    "displacy.render(sents[9], style='dep', jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
